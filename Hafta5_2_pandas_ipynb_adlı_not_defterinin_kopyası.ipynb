{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emreekinci/ANN/blob/main/Hafta5_2_pandas_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "QEh2kZoZH1XL"
      },
      "source": [
        "# Data Preprocessing\n",
        ":label:`sec_pandas`\n",
        "\n",
        "So far we have introduced a variety of techniques for manipulating data that are already stored in tensors.\n",
        "To apply deep learning to solving real-world problems,\n",
        "we often begin with preprocessing raw data, rather than those nicely prepared data in the tensor format.\n",
        "Among popular data analytic tools in Python, the `pandas` package is commonly used.\n",
        "Like many other extension packages in the vast ecosystem of Python,\n",
        "`pandas` can work together with tensors.\n",
        "So, we will briefly walk through steps for preprocessing raw data with `pandas`\n",
        "and converting them into the tensor format.\n",
        "We will cover more data preprocessing techniques in later chapters.\n",
        "\n",
        "## Reading the Dataset\n",
        "\n",
        "As an example,\n",
        "we begin by (**creating an artificial dataset that is stored in a\n",
        "csv (comma-separated values) file**)\n",
        "`../data/house_tiny.csv`. Data stored in other\n",
        "formats may be processed in similar ways.\n",
        "\n",
        "Below we write the dataset row by row into a csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "pytorch"
        ],
        "id": "K-9b5LpRH1XN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
        "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
        "    f.write('2,NA,106000\\n')\n",
        "    f.write('4,NA,178100\\n')\n",
        "    f.write('NA,NA,140000\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 2,
        "id": "dc-8GbFwH1XO"
      },
      "source": [
        "To [**load the raw dataset from the created csv file**],\n",
        "we import the `pandas` package and invoke the `read_csv` function.\n",
        "This dataset has four rows and three columns, where each row describes the number of rooms (\"NumRooms\"), the alley type (\"Alley\"), and the price (\"Price\") of a house.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "7oWdXPAeH1XO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5949eac8-bf74-4866-a5de-9a931d801f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley   Price\n",
            "0       NaN  Pave  127500\n",
            "1       2.0   NaN  106000\n",
            "2       4.0   NaN  178100\n",
            "3       NaN   NaN  140000\n"
          ]
        }
      ],
      "source": [
        "# If pandas is not installed, just uncomment the following line:\n",
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Price\"].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBqaauDg5OyZ",
        "outputId": "1cfc4a4c-2328-4e64-eeed-e618a91cdf6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137900.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "f0joDQYtH1XP"
      },
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "Note that \"NaN\" entries are missing values.\n",
        "To handle missing data, typical methods include *imputation* and *deletion*,\n",
        "where imputation replaces missing values with substituted ones,\n",
        "while deletion ignores missing values. Here we will consider imputation.\n",
        "\n",
        "By integer-location based indexing (`iloc`), we split `data` into `inputs` and `outputs`,\n",
        "where the former takes the first two columns while the latter only keeps the last column.\n",
        "For numerical values in `inputs` that are missing,\n",
        "we [**replace the \"NaN\" entries with the mean value of the same column.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "MFtrlRZhH1XP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2484fd47-d366-4120-fbb3-60fd53a4cc5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       3.0   NaN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "NnCtlln7H1XQ"
      },
      "source": [
        "[**For categorical or discrete values in `inputs`, we consider \"NaN\" as a category.**]\n",
        "Since the \"Alley\" column only takes two types of categorical values \"Pave\" and \"NaN\",\n",
        "`pandas` can automatically convert this column to two columns \"Alley_Pave\" and \"Alley_nan\".\n",
        "A row whose alley type is \"Pave\" will set values of \"Alley_Pave\" and \"Alley_nan\" to 1 and 0.\n",
        "A row with a missing alley type will set their values to 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "JZyMR4H3H1XQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce234236-b7fa-4eed-ada1-7151989964f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0       3.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           0          1\n",
            "3       3.0           0          1\n"
          ]
        }
      ],
      "source": [
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "WWxwfinqH1XQ"
      },
      "source": [
        "## Conversion to the Tensor Format\n",
        "\n",
        "Now that [**all the entries in `inputs` and `outputs` are numerical, they can be converted to the tensor format.**]\n",
        "Once data are in this format, they can be further manipulated with those tensor functionalities that we have introduced in :numref:`sec_ndarray`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "K8lxAReJH1XR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242f403c-39f3-4128-926c-b87b5021c808"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 1., 0.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 0., 1.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
        "X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "9CEexbEJH1XR"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Like many other extension packages in the vast ecosystem of Python, `pandas` can work together with tensors.\n",
        "* Imputation and deletion can be used to handle missing data.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "Create a raw dataset with more rows and columns.\n",
        "\n",
        "1. Delete the column with the most missing values.\n",
        "2. Convert the preprocessed dataset to the tensor format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "id": "BphoO1I-H1XR"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/29)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Hafta5 - 2 pandas.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}